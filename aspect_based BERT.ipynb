{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "Model built successfully\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertModel\n",
    "\n",
    "# Test loading a simple model\n",
    "try:\n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    print(\"Model loaded successfully\")\n",
    "    \n",
    "    # Explicitly build the model to ensure it doesn't have issues\n",
    "    dummy_input_ids = tf.keras.Input(shape=(200,), dtype=tf.int32)\n",
    "    dummy_attention_mask = tf.keras.Input(shape=(200,), dtype=tf.int32)\n",
    "    _ = bert_model([dummy_input_ids, dummy_attention_mask])\n",
    "\n",
    "    print(\"Model built successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (1.26.4)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (4.44.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (2.17.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting glob2\n",
      "  Downloading glob2-0.7.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (74.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.0-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.53.1-cp312-cp312-win_amd64.whl.metadata (165 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.8.0)\n",
      "Requirement already satisfied: namex in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\andyb\\desktop\\coding files\\pointview\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 6.3/11.5 MB 32.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 31.2 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.5.1-cp312-cp312-win_amd64.whl (10.9 MB)\n",
      "   ---------------------------------------- 0.0/10.9 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 9.7/10.9 MB 46.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.9/10.9 MB 42.7 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.9.2-cp312-cp312-win_amd64.whl (7.8 MB)\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 7.8/7.8 MB 37.3 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.0-cp312-cp312-win_amd64.whl (218 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.53.1-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 41.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading kiwisolver-1.4.5-cp312-cp312-win_amd64.whl (56 kB)\n",
      "Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 29.0 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 6.0/44.5 MB 30.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 13.4/44.5 MB 33.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 22.3/44.5 MB 37.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 31.2/44.5 MB 38.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.5/44.5 MB 38.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 38.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 36.3 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Building wheels for collected packages: glob2\n",
      "  Building wheel for glob2 (setup.py): started\n",
      "  Building wheel for glob2 (setup.py): finished with status 'done'\n",
      "  Created wheel for glob2: filename=glob2-0.7-py2.py3-none-any.whl size=9311 sha256=f53a664f13a782eaf6097aefa019e3e1f29e0530a29e844168a252275ba2f1c9\n",
      "  Stored in directory: c:\\users\\andyb\\appdata\\local\\pip\\cache\\wheels\\fb\\b3\\7b\\71827dcd17a71be7a8b7adf9f30a4200b612a903d7d8af3442\n",
      "Successfully built glob2\n",
      "Installing collected packages: pytz, glob2, tzdata, threadpoolctl, scipy, pyparsing, pillow, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, pandas, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.53.1 glob2-0.7 joblib-1.4.2 kiwisolver-1.4.5 matplotlib-3.9.2 pandas-2.2.2 pillow-10.4.0 pyparsing-3.1.4 pytz-2024.1 scikit-learn-1.5.1 scipy-1.14.1 threadpoolctl-3.5.0 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn transformers tensorflow matplotlib glob2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 29 CSV files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andyb\\Desktop\\Coding Files\\PointView\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_bert_model_3' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_3' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 200), dtype=int32, sparse=False, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, 200), dtype=int32, sparse=False, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m attention_masks \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m200\u001b[39m,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Pass input_ids and attention_masks as separate arguments\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m bert_output \u001b[38;5;241m=\u001b[39m \u001b[43mbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_masks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# [1] is the pooled output\u001b[39;00m\n\u001b[0;32m     87\u001b[0m dense \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(bert_output)\n\u001b[0;32m     88\u001b[0m dropout \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.3\u001b[39m)(dense)\n",
      "File \u001b[1;32mc:\\Users\\andyb\\Desktop\\Coding Files\\PointView\\.venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\andyb\\Desktop\\Coding Files\\PointView\\.venv\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:436\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m--> 436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m \u001b[43minput_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args_and_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[1;32mc:\\Users\\andyb\\Desktop\\Coding Files\\PointView\\.venv\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:513\u001b[0m, in \u001b[0;36minput_processing\u001b[1;34m(func, config, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m         output[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 513\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(main_input, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(main_input):\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;66;03m# EagerTensors don't allow to use the .name property so we check for a real Tensor\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_bert_model_3' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_3' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 200), dtype=int32, sparse=False, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, 200), dtype=int32, sparse=False, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Load and concatenate all CSV files into a single DataFrame\n",
    "def load_aspect_data(path):\n",
    "    all_files = glob.glob(path)\n",
    "    all_data = []\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename)\n",
    "        all_data.append(df)\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"Loaded {len(all_files)} CSV files.\")\n",
    "    return combined_df\n",
    "\n",
    "aspect_path = r\"C:\\Users\\andyb\\Desktop\\Coding Files\\PointView\\datasets\\aspect_based_dataset\\*.csv\"\n",
    "aspect_df = load_aspect_data(aspect_path)\n",
    "\n",
    "# Ensure 'Classification' is categorical and has correct unique values\n",
    "specific_kpis = ['food', 'staff', 'comfort & facilities', 'value for money']\n",
    "\n",
    "# Binary encoding for each KPI in 'Classification' column\n",
    "def check_kpi(classification, kpi):\n",
    "    if isinstance(classification, str):\n",
    "        return 1 if kpi.lower() in classification.lower() else 0\n",
    "    return 0\n",
    "\n",
    "for kpi in specific_kpis:\n",
    "    aspect_df[kpi] = aspect_df['Classification'].apply(lambda x: check_kpi(x, kpi))\n",
    "\n",
    "# Prepare features (X) and labels (y)\n",
    "X = aspect_df['Opinion'].values\n",
    "y = aspect_df[specific_kpis].values\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to tokenize and encode data\n",
    "def bert_encode(texts, tokenizer, max_len=200):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for text in texts:\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "\n",
    "    return {\n",
    "        'input_ids': tf.concat(input_ids, axis=0),\n",
    "        'attention_mask': tf.concat(attention_masks, axis=0)\n",
    "    }\n",
    "\n",
    "X_encoded = bert_encode(X, bert_tokenizer)\n",
    "\n",
    "# Convert TensorFlow tensors to NumPy arrays before splitting\n",
    "X_input_ids = X_encoded['input_ids'].numpy()\n",
    "X_attention_masks = X_encoded['attention_mask'].numpy()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_ids, X_test_ids, y_train, y_test = train_test_split(X_input_ids, y, test_size=0.2, random_state=42)\n",
    "attention_train, attention_test = train_test_split(X_attention_masks, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load BERT model\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Build the BERT-based model\n",
    "input_ids = tf.keras.Input(shape=(200,), dtype=tf.int32, name='input_ids')\n",
    "attention_masks = tf.keras.Input(shape=(200,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "# Pass input_ids and attention_masks as separate arguments\n",
    "bert_output = bert_model(input_ids=input_ids, attention_mask=attention_masks)[1]  # [1] is the pooled output\n",
    "dense = Dense(64, activation='relu')(bert_output)\n",
    "dropout = Dropout(0.3)(dense)\n",
    "output = Dense(len(specific_kpis), activation='sigmoid')(dropout)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, attention_masks], outputs=output)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Train the BERT model\n",
    "history = model.fit(\n",
    "    [X_train_ids, attention_train],\n",
    "    y_train,\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping, lr_reducer]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate([X_test_ids, attention_test], y_test)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "y_pred = model.predict([X_test_ids, attention_test])\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_binary, target_names=specific_kpis))\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Over Epochs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy Over Epochs')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Function to predict KPI likelihoods for new data using BERT\n",
    "def predict_kpi_likelihoods(text):\n",
    "    encoded_text = bert_encode([text], bert_tokenizer)\n",
    "    prediction = model.predict([encoded_text['input_ids'].numpy(), encoded_text['attention_mask'].numpy()])[0]\n",
    "    return {kpi: float(likelihood) for kpi, likelihood in zip(specific_kpis, prediction)}\n",
    "\n",
    "# Test the model on a sample review\n",
    "sample_review = \"The room was clean and comfortable, but the staff was not very friendly. The food was excellent.\"\n",
    "predicted_likelihoods = predict_kpi_likelihoods(sample_review)\n",
    "print(\"\\nPredicted KPI likelihoods for the sample review:\")\n",
    "for kpi, likelihood in predicted_likelihoods.items():\n",
    "    print(f\"{kpi}: {likelihood:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
