{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and preprocessing of raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Define directories for each dataset\n",
    "directories = {\n",
    "    'agoda_hotel_reviews': (1, 10),  \n",
    "    'tripadvisor_hotel_reviews': (1, 5),\n",
    "    'klook_hotel_reviews': (1, 5),  \n",
    "    'booking_hotel_reviews': (1, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and normalize data\n",
    "def load_and_normalize_data():\n",
    "    all_reviews = []\n",
    "    for directory, (min_score, max_score) in directories.items():           \n",
    "        path = os.path.join('../raw data', directory)\n",
    "        for filename in os.listdir(path):\n",
    "            if filename.endswith('.csv'):\n",
    "                df = pd.read_csv(os.path.join(path, filename))\n",
    "                scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "                df['normalized_score'] = scaler.fit_transform(df[['Review Score']])\n",
    "                all_reviews.append(df)\n",
    "    return pd.concat(all_reviews, ignore_index=True)\n",
    "\n",
    "# Load and normalize data\n",
    "df = load_and_normalize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: No features in text.\n",
      "error: No features in text.\n",
      "error: No features in text.\n",
      "error: No features in text.\n",
      "error: No features in text.\n",
      "error: No features in text.\n",
      "error: No features in text.\n",
      "error: No features in text.\n",
      "error: No features in text.\n",
      "error: No features in text.\n",
      "error: No features in text.\n",
      "Removed reviews:\n",
      "11                                     Excellent\\r\\n \\r\\n \n",
      "31       Napakaganda ang mura pa dito ulit ako mag ssta...\n",
      "40                              Brilliant hotel.\\r\\n \\r\\n \n",
      "43                                         Good \\r\\n \\r\\n \n",
      "45                    No frills, reliable hotel.\\r\\n \\r\\n \n",
      "                               ...                        \n",
      "10089       \\r\\n Buffet breakfast and dinner\\r\\n No issues\n",
      "10134                \\r\\n very good room attendant\\r\\n n/a\n",
      "10152                                     \\r\\n Buffet\\r\\n \n",
      "10155    \\r\\n feels like home\\r\\n carpets and rooms nee...\n",
      "10219                                 \\r\\n None\\r\\n Casino\n",
      "Name: Review Content, Length: 443, dtype: object\n",
      "      Review Provider  Review ID  \\\n",
      "0               Agoda  831639368   \n",
      "1               Agoda  830646554   \n",
      "2               Agoda  830862563   \n",
      "3               Agoda  830828036   \n",
      "4               Agoda  823596890   \n",
      "...               ...        ...   \n",
      "10237             NaN  493909284   \n",
      "10238             NaN  493909298   \n",
      "10239             NaN  493909242   \n",
      "10240             NaN  475015759   \n",
      "10241             NaN  475015758   \n",
      "\n",
      "                                          Review Content  Review Score  \\\n",
      "0      The hotel's facilities were top notch, from th...           9.6   \n",
      "1      I enjoyed my stay at the Bai Hotel. The prices...          10.0   \n",
      "2                            My favorite hotel\\r\\n \\r\\n           10.0   \n",
      "3      This hotel was so accommodating. Good staff, g...          10.0   \n",
      "4                             Well recommended\\r\\n \\r\\n           10.0   \n",
      "...                                                  ...           ...   \n",
      "10237  \\r\\n Kindness and great service\\r\\n Internet Poor           9.0   \n",
      "10238  \\r\\n It’s located at the heart of the city. Ve...           9.0   \n",
      "10239  \\r\\n It looks and smells clean from the lobby ...           5.0   \n",
      "10240  \\r\\n Room,Location ,pool,Breakfast\\r\\n Slow Wi...           8.0   \n",
      "10241  \\r\\n I have been going to the Waterfront for m...          10.0   \n",
      "\n",
      "                     Review Time  normalized_score  \\\n",
      "0      2024-07-16T09:26:00+07:00          0.950000   \n",
      "1      2024-07-15T12:05:00+07:00          1.000000   \n",
      "2      2024-07-15T07:56:00+07:00          1.000000   \n",
      "3      2024-07-15T04:07:00+07:00          1.000000   \n",
      "4      2024-07-14T07:00:00+07:00          1.000000   \n",
      "...                          ...               ...   \n",
      "10237  2022-02-20T05:45:27+07:00          0.888889   \n",
      "10238  2022-01-21T06:18:20+07:00          0.888889   \n",
      "10239  2022-01-17T10:11:10+07:00          0.444444   \n",
      "10240  2022-01-13T02:15:58+07:00          0.777778   \n",
      "10241  2022-01-09T22:15:34+07:00          1.000000   \n",
      "\n",
      "                                         cleaned_content  \n",
      "0      hotel facility top notch well maintained ameni...  \n",
      "1      enjoyed stay bai hotel price reasonable room n...  \n",
      "2                                         favorite hotel  \n",
      "3      hotel accommodating good staff great ambiance ...  \n",
      "4                                       well recommended  \n",
      "...                                                  ...  \n",
      "10237               kindness great service internet poor  \n",
      "10238  ’ located heart city accessible restaurant sti...  \n",
      "10239  look smell clean lobby room mountaincity view ...  \n",
      "10240  roomlocation poolbreakfast slow wifi cable was...  \n",
      "10241  going waterfront many year whilst visiting phi...  \n",
      "\n",
      "[9799 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to lemmatize text and check if it's in English\n",
    "# for identifying english reviews\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        # Check if the review is in English\n",
    "        lang = detect(text)\n",
    "        if lang != 'en':\n",
    "            return None  # Return None if not in English\n",
    "\n",
    "        # Step 1: Convert text to lowercase\n",
    "        text = text.lower()\n",
    "\n",
    "        # Step 2: Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        # Step 3: Tokenization\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "\n",
    "        # Step 4: Remove stop words\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        # Step 5: Lemmatization\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "        # Return the processed text as a single string\n",
    "        return ' '.join(lemmatized_tokens)\n",
    "\n",
    "    except LangDetectException as e:\n",
    "        # If language detection fails, return None\n",
    "        print(f\"error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply preprocessing to the DataFrame column\n",
    "df['cleaned_content'] = df['Review Content'].apply(preprocess_text)\n",
    "\n",
    "# Identify and print the removed reviews\n",
    "removed_reviews = df[df['cleaned_content'].isnull()]['Review Content']\n",
    "print(\"Removed reviews:\")\n",
    "print(removed_reviews)\n",
    "\n",
    "# Drop rows where 'cleaned_content' is None (non-English reviews)\n",
    "df = df.dropna(subset=['cleaned_content'])\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        2\n",
      "1        2\n",
      "2        2\n",
      "3        2\n",
      "4        2\n",
      "        ..\n",
      "10237    2\n",
      "10238    2\n",
      "10239    1\n",
      "10240    2\n",
      "10241    2\n",
      "Name: label, Length: 9799, dtype: int64\n",
      "  Review Provider  Review ID  \\\n",
      "0           Agoda  831639368   \n",
      "1           Agoda  830646554   \n",
      "2           Agoda  830862563   \n",
      "3           Agoda  830828036   \n",
      "4           Agoda  823596890   \n",
      "\n",
      "                                      Review Content  Review Score  \\\n",
      "0  The hotel's facilities were top notch, from th...           9.6   \n",
      "1  I enjoyed my stay at the Bai Hotel. The prices...          10.0   \n",
      "2                        My favorite hotel\\r\\n \\r\\n           10.0   \n",
      "3  This hotel was so accommodating. Good staff, g...          10.0   \n",
      "4                         Well recommended\\r\\n \\r\\n           10.0   \n",
      "\n",
      "                 Review Time  normalized_score  \\\n",
      "0  2024-07-16T09:26:00+07:00              0.95   \n",
      "1  2024-07-15T12:05:00+07:00              1.00   \n",
      "2  2024-07-15T07:56:00+07:00              1.00   \n",
      "3  2024-07-15T04:07:00+07:00              1.00   \n",
      "4  2024-07-14T07:00:00+07:00              1.00   \n",
      "\n",
      "                                     cleaned_content  label  \n",
      "0  hotel facility top notch well maintained ameni...      2  \n",
      "1  enjoyed stay bai hotel price reasonable room n...      2  \n",
      "2                                     favorite hotel      2  \n",
      "3  hotel accommodating good staff great ambiance ...      2  \n",
      "4                                   well recommended      2  \n",
      "       normalized_score        label\n",
      "count       9799.000000  9799.000000\n",
      "mean           0.853581     1.777834\n",
      "std            0.222705     0.501411\n",
      "min            0.000000     0.000000\n",
      "25%            0.777778     2.000000\n",
      "50%            1.000000     2.000000\n",
      "75%            1.000000     2.000000\n",
      "max            1.000000     2.000000\n"
     ]
    }
   ],
   "source": [
    "# Convert normalized scores to binary labels (1 for positive, 0 for negative)\n",
    "df['label'] = df['normalized_score'].apply(lambda x: 0 if x <= 0.25 else (2 if x >= 0.75 else 1))\n",
    "print(df['label'])\n",
    "print(df.head())\n",
    "\n",
    "print(df[['normalized_score', 'label']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive reviews: 8007\n",
      "Negative reviews: 385\n",
      "Neutral reviews: 1407\n",
      "Total: 9799\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each label\n",
    "positive_count = (df['label'] == 2).sum()\n",
    "negative_count = (df['label'] == 0).sum()\n",
    "neutral_count = (df['label'] == 1).sum()\n",
    "\n",
    "# Print the counts\n",
    "print(f'Positive reviews: {positive_count}')\n",
    "print(f'Negative reviews: {negative_count}')\n",
    "print(f'Neutral reviews: {neutral_count}')\n",
    "print(f\"Total: {df['label'].count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the entire dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    df['cleaned_content'], \n",
    "    df['label'], \n",
    "    test_size=0.3, \n",
    "    stratify=df['label'], \n",
    "    random_state=42\n",
    ")\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train_raw)\n",
    "\n",
    "# Convert texts to sequences\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train_raw)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test_raw)\n",
    "\n",
    "# Pad sequences to ensure uniform input size\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=100)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=100)\n",
    "\n",
    "\n",
    "# # Convert texts to sequences\n",
    "# sequences = tokenizer.texts_to_sequences(df['cleaned_content'])\n",
    "# padded_sequences = pad_sequences(sequences, maxlen=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving of cleaned and preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Predator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Computed output size would be negative. Received `inputs shape=(None, 1, 128)`, `kernel shape=(5, 128, 64)`, `dilation_rate=[1]`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Model Training\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Model Evaluation\u001b[39;00m\n\u001b[0;32m     24\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\Predator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Predator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\ops\\operation_utils.py:221\u001b[0m, in \u001b[0;36mcompute_conv_output_shape\u001b[1;34m(input_shape, filters, kernel_size, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output_spatial_shape)):\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m none_dims \u001b[38;5;129;01mand\u001b[39;00m output_spatial_shape[i] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    222\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputed output size would be negative. Received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`inputs shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`kernel shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`dilation_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdilation_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    226\u001b[0m             )\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m padding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m padding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcausal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    228\u001b[0m     output_spatial_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor((spatial_shape \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m strides) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Computed output size would be negative. Received `inputs shape=(None, 1, 128)`, `kernel shape=(5, 128, 64)`, `dilation_rate=[1]`."
     ]
    }
   ],
   "source": [
    "# Model creation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=100),\n",
    "    Conv1D(filters=64, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),  # Corrected placement\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')  # Assuming 3 classes for multi-class classification\n",
    "])\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Model Compilation\n",
    "model.compile(optimizer=Adam(learning_rate = 0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Model Training\n",
    "history = model.fit(X_train_padded, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Model Evaluation\n",
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')  # Rounded to 4 decimal places for clarity\n",
    "\n",
    "# Plot training & validation accuracy and loss values\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy Over Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss Over Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Review: The hotel staff was incredibly helpful and the room was clean and spacious. Definitely a positive experience!\n",
      "Actual Score: 1.00\n",
      "Predicted Label: Positive\n",
      "Negative Probability: 0.00\n",
      "Neutral Probability: 0.02\n",
      "Positive Probability: 0.98\n",
      "--------------------------------------------------\n",
      "Review: The location was good, but the room had a strange smell and the service was just okay.\n",
      "Actual Score: 0.60\n",
      "Predicted Label: Neutral\n",
      "Negative Probability: 0.11\n",
      "Neutral Probability: 0.53\n",
      "Positive Probability: 0.36\n",
      "--------------------------------------------------\n",
      "Review: I had a terrible stay. The room was dirty and the staff was rude. Not worth the price.\n",
      "Actual Score: 0.20\n",
      "Predicted Label: Neutral\n",
      "Negative Probability: 0.18\n",
      "Neutral Probability: 0.62\n",
      "Positive Probability: 0.20\n",
      "--------------------------------------------------\n",
      "Review: Amazing experience! The view from the room was breathtaking and the food at the restaurant was top-notch.\n",
      "Actual Score: 1.00\n",
      "Predicted Label: Positive\n",
      "Negative Probability: 0.01\n",
      "Neutral Probability: 0.05\n",
      "Positive Probability: 0.94\n",
      "--------------------------------------------------\n",
      "Review: The room was decent, but the Wi-Fi was slow and unreliable. It was an average stay overall.\n",
      "Actual Score: 0.50\n",
      "Predicted Label: Neutral\n",
      "Negative Probability: 0.15\n",
      "Neutral Probability: 0.60\n",
      "Positive Probability: 0.25\n",
      "--------------------------------------------------\n",
      "Review: Terrible service! We waited over an hour for our room to be ready and the staff was not apologetic.\n",
      "Actual Score: 0.30\n",
      "Predicted Label: Neutral\n",
      "Negative Probability: 0.12\n",
      "Neutral Probability: 0.57\n",
      "Positive Probability: 0.31\n",
      "--------------------------------------------------\n",
      "Review: The hotel was in a perfect location, close to all the major attractions. The room was comfortable and well-maintained.\n",
      "Actual Score: 0.90\n",
      "Predicted Label: Positive\n",
      "Negative Probability: 0.01\n",
      "Neutral Probability: 0.08\n",
      "Positive Probability: 0.91\n",
      "--------------------------------------------------\n",
      "Review: The facilities were outdated, and the air conditioning barely worked. I was disappointed with my stay.\n",
      "Actual Score: 0.40\n",
      "Predicted Label: Neutral\n",
      "Negative Probability: 0.11\n",
      "Neutral Probability: 0.54\n",
      "Positive Probability: 0.35\n",
      "--------------------------------------------------\n",
      "Review: Great value for money! The hotel offered a lot of amenities and the staff was very friendly.\n",
      "Actual Score: 0.80\n",
      "Predicted Label: Positive\n",
      "Negative Probability: 0.00\n",
      "Neutral Probability: 0.02\n",
      "Positive Probability: 0.98\n",
      "--------------------------------------------------\n",
      "Review: The breakfast was good, but the room was small and the bed was uncomfortable. It was an okay stay.\n",
      "Actual Score: 0.60\n",
      "Predicted Label: Neutral\n",
      "Negative Probability: 0.13\n",
      "Neutral Probability: 0.58\n",
      "Positive Probability: 0.28\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Example input reviews\n",
    "new_reviews = [\n",
    "    {\"review\": \"The hotel staff was incredibly helpful and the room was clean and spacious. Definitely a positive experience!\", \"score\": 1.0},\n",
    "    {\"review\": \"The location was good, but the room had a strange smell and the service was just okay.\", \"score\": 0.6},\n",
    "    {\"review\": \"I had a terrible stay. The room was dirty and the staff was rude. Not worth the price.\", \"score\": 0.2},\n",
    "    {\"review\": \"Amazing experience! The view from the room was breathtaking and the food at the restaurant was top-notch.\", \"score\": 1.0},\n",
    "    {\"review\": \"The room was decent, but the Wi-Fi was slow and unreliable. It was an average stay overall.\", \"score\": 0.5},\n",
    "    {\"review\": \"Terrible service! We waited over an hour for our room to be ready and the staff was not apologetic.\", \"score\": 0.3},\n",
    "    {\"review\": \"The hotel was in a perfect location, close to all the major attractions. The room was comfortable and well-maintained.\", \"score\": 0.9},\n",
    "    {\"review\": \"The facilities were outdated, and the air conditioning barely worked. I was disappointed with my stay.\", \"score\": 0.4},\n",
    "    {\"review\": \"Great value for money! The hotel offered a lot of amenities and the staff was very friendly.\", \"score\": 0.8},\n",
    "    {\"review\": \"The breakfast was good, but the room was small and the bed was uncomfortable. It was an okay stay.\", \"score\": 0.6}\n",
    "]\n",
    "\n",
    "# Define a function to preprocess new input data\n",
    "def preprocess_new_data(new_data):\n",
    "    # Apply the same preprocessing function\n",
    "    cleaned_data = [preprocess_text(entry[\"review\"]) for entry in new_data]\n",
    "    \n",
    "    # Convert to sequences using the trained tokenizer\n",
    "    sequences = tokenizer.texts_to_sequences(cleaned_data)\n",
    "    \n",
    "    # Pad the sequences\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=100)  # Use the same maxlen as your training data\n",
    "\n",
    "    return padded_sequences\n",
    "\n",
    "# Prepare reviews for prediction\n",
    "padded_sequences = preprocess_new_data(new_reviews)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(padded_sequences)\n",
    "\n",
    "# Interpreting the predictions\n",
    "for i, prediction in enumerate(predictions):\n",
    "    predicted_label = np.argmax(prediction)  # Get the index of the highest probability\n",
    "    predicted_score = prediction[predicted_label]  # The probability of the predicted class\n",
    "    actual_score = new_reviews[i][\"score\"]\n",
    "\n",
    "    # Assign sentiment based on the predicted label\n",
    "    sentiment_labels = ['Negative', 'Neutral', 'Positive']\n",
    "    sentiment = sentiment_labels[predicted_label]\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Review: {new_reviews[i]['review']}\")\n",
    "    print(f\"Actual Score: {actual_score:.2f}\")\n",
    "    print(f\"Predicted Label: {sentiment}\")\n",
    "    print(f\"Negative Probability: {prediction[0]:.2f}\")\n",
    "    print(f\"Neutral Probability: {prediction[1]:.2f}\")\n",
    "    print(f\"Positive Probability: {prediction[2]:.2f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# import os\n",
    "\n",
    "# # Assuming `model` is your Keras model\n",
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# file_name = f'saved_models/general_sentiment_softmax_{timestamp}.keras'\n",
    "\n",
    "# # Make sure the directory exists\n",
    "# os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "\n",
    "# # Save the model with the unique file name\n",
    "# model.save(file_name)\n",
    "# print(f\"Model saved as {file_name}\")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
