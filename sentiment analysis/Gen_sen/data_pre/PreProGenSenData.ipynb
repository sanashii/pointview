{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Function to load and normalize data\n",
    "def load_and_normalize_data(directories):\n",
    "    hotel_dfs = {}\n",
    "    \n",
    "    for directory in directories:           \n",
    "        path = os.path.join('../../../raw data', directory)\n",
    "        \n",
    "        for filename in os.listdir(path):\n",
    "            if filename.endswith('.csv'):\n",
    "                # Extract hotel name from filename by removing undesired part\n",
    "                hotel_name = os.path.splitext(filename)[0].replace('_reviews_2022_2024', '')\n",
    "                \n",
    "                df = pd.read_csv(os.path.join(path, filename))\n",
    "                \n",
    "                # Normalize the Review Score\n",
    "                scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "                df['normalized_score'] = scaler.fit_transform(df[['Review Score']])\n",
    "\n",
    "                # Add a new column for hotel name\n",
    "                df['Hotel'] = hotel_name\n",
    "                \n",
    "                # Concatenate to the hotel DataFrame\n",
    "                if hotel_name in hotel_dfs:\n",
    "                    hotel_dfs[hotel_name] = pd.concat([hotel_dfs[hotel_name], df], ignore_index=True)\n",
    "                else:\n",
    "                    hotel_dfs[hotel_name] = df.reset_index(drop=True)\n",
    "\n",
    "    return hotel_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from langdetect import DetectorFactory\n",
    "from collections import Counter\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        #Return None if there are less than 10 words in the review\n",
    "        min_length = 10\n",
    "        if len(text.split()) < min_length:\n",
    "            return None\n",
    "        # Check if the review is in English\n",
    "        lang = detect(text)\n",
    "        if lang != 'en':\n",
    "            return None  # Return None if not in English\n",
    "        # Convert text to lowercase\n",
    "        \n",
    "        text = text.lower()\n",
    "\n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        # Remove emojis\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "        # Remove numbers\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "        # Tokenization\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        # Count tokens before removing stop words and lemmatization\n",
    "\n",
    "        # Remove stop words\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        # Lemmatization\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "        processed_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "        # Remove extra whitespace\n",
    "        return re.sub(r'\\s+', ' ', processed_text).strip()\n",
    "\n",
    "    except LangDetectException as e:\n",
    "        # If language detection fails, return None\n",
    "        # print(f\"error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directories = [\n",
    "    'agoda_hotel_reviews',  \n",
    "    'tripadvisor_hotel_reviews',\n",
    "    'klook_hotel_reviews',  \n",
    "    'booking_hotel_reviews'\n",
    "]\n",
    "# Load and normalize data\n",
    "hotel_dfs = load_and_normalize_data(directories)\n",
    "\n",
    "\n",
    "for hotel, df in hotel_dfs.items():\n",
    "    # Apply preprocessing to the DataFrame's 'Review Content' column\n",
    "    df['cleaned_content'] = df['Review Content'].apply(preprocess_text)\n",
    "    hotel_dfs[hotel] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of labels\n",
    "input_data_dfs = {}\n",
    "for hotel, df in hotel_dfs.items():\n",
    "    df['label'] = df['normalized_score'].apply(lambda x: 0 if x <= 0.25 else (2 if x >= 0.75 else 1))\n",
    "    # Identify and print the removed reviews (non-English)\n",
    "    removed_reviews = df[df['cleaned_content'].isnull()]['Review Content']\n",
    "    # Drop rows where 'cleaned_content' is None (non-English reviews)\n",
    "    df = df.dropna(subset=['cleaned_content'])\n",
    "    \n",
    "\n",
    "    # Update the DataFrame in the dictionary    \n",
    "    input_data_dfs[hotel] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotel data and input data exported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure the directories exist before saving the CSV files\n",
    "os.makedirs('hotel_data', exist_ok=True)\n",
    "os.makedirs('input_data', exist_ok=True)\n",
    "\n",
    "# Exporting hotel_dfs\n",
    "for hotel_name, df in hotel_dfs.items():\n",
    "    df.to_csv(f'hotel_data/{hotel_name}_hotel_data.csv', index=False)\n",
    "\n",
    "# Exporting input_data_dfs\n",
    "for hotel_name, df in input_data_dfs.items():\n",
    "    df.to_csv(f'input_data/{hotel_name}_input_data.csv', index=False)\n",
    "\n",
    "print(\"Hotel data and input data exported successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
