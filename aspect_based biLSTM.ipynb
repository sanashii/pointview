{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 29 CSV files.\n",
      "Total number of rows: 8626\n",
      "Columns: ['Opinion', 'Classification']\n",
      "\n",
      "First few rows:\n",
      "                                             Opinion  \\\n",
      "0  We stayed for a week and could not fault it at...   \n",
      "1  This resort is beautiful. The rooms are fabulo...   \n",
      "2  i never fail to visit Shangrila Boracay eveyti...   \n",
      "3  This is really a 4.5 star review. Had a chance...   \n",
      "4  Transfers - On arrival at the airport we were ...   \n",
      "\n",
      "                       Classification  \n",
      "0                      Staff:Location  \n",
      "1           Food:Comfort & Facilities  \n",
      "2                       Location:Food  \n",
      "3  Comfort & Facilities:Food:Location  \n",
      "4     Comfort & Facilities:Food:Staff  \n",
      "\n",
      "Data types and non-null counts:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8626 entries, 0 to 8625\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Opinion         8626 non-null   object\n",
      " 1   Classification  8508 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 134.9+ KB\n",
      "None\n",
      "\n",
      "Unique values in Classification column:\n",
      "['Staff:Location' 'Food:Comfort & Facilities' 'Location:Food'\n",
      " 'Comfort & Facilities:Food:Location' 'Comfort & Facilities:Food:Staff'\n",
      " 'Staff:Food' 'Staff' 'Staff:Location:Food'\n",
      " 'Comfort & Facilities:Location:Food'\n",
      " 'Comfort & Facilities:Value for money:Staff' 'Location:Staff'\n",
      " 'Location:Comfort & Facilities:Food' 'Food:Location'\n",
      " 'Comfort & Facilities' 'Food:Comfort & Facilities:Location'\n",
      " 'Food:Location:Staff' 'Food:Comfort & Facilities:Staff'\n",
      " 'Location:Food:Staff' 'Food:Staff:Comfort & Facilities'\n",
      " 'Staff:Value for money:Food' 'Food:Location:Comfort & Facilities'\n",
      " 'Comfort & Facilities:Food' 'Food:Staff'\n",
      " 'Comfort & Facilities:Location:Staff' 'Value for money:Food:Staff'\n",
      " 'Location:Comfort & Facilities' 'Comfort & Facilities:Value for money'\n",
      " 'Value for money:Food:Comfort & Facilities'\n",
      " 'Comfort & Facilities:Location' 'Staff:Comfort & Facilities:Location'\n",
      " 'Comfort & Facilities:Staff:Location' 'Staff:Food:Location'\n",
      " 'Staff:Comfort & Facilities:Food' 'Food:Staff:Value for money' 'Location'\n",
      " 'Comfort & Facilities:Value for money:Food' 'Food:Value for money:Staff'\n",
      " 'Staff:Value for money' 'Food:Value for money:Location'\n",
      " 'Food:Value for money' 'Staff:Cleanliness:Value for money'\n",
      " 'Staff:Comfort & Facilities' 'Food:Value for money:Comfort & Facilities'\n",
      " 'Value for money' 'Food' 'Food:Staff:Location'\n",
      " 'Location:Food:Comfort & Facilities' 'Value for money:Staff:Food'\n",
      " 'Location:Comfort & Facilities:Value for money'\n",
      " 'Staff:Food:Comfort & Facilities' 'Value for money:Comfort & Facilities'\n",
      " 'Comfort & Facilities:Value for money:Location'\n",
      " 'Comfort & Facilities:Staff' 'Food:Comfort & Facilities:Value for money'\n",
      " 'Comfort & Facilities:Cleanliness' 'Location:Staff:Food' nan\n",
      " 'Staff:Cleanliness:Location' 'Location:Value for money:Food'\n",
      " 'Value for money:Comfort & Facilities:Food' 'Cleanliness'\n",
      " 'Comfort & Facilities:Location:Value for money' 'Staff:Cleanliness:Food'\n",
      " 'Value for money:Food' 'Comfort & Facilities:Staff:Cleanliness'\n",
      " 'Staff:Location:Comfort & Facilities' 'Staff:Food:Value for money'\n",
      " 'Comfort & Facilities:Cleanliness:Value for money'\n",
      " 'Comfort & Facilities:Food:Value for money' 'Staff:Cleanliness'\n",
      " 'Value for money:Staff' 'Location:Staff:Comfort & Facilities'\n",
      " 'Value for money:Location' 'Staff:Internet:Food'\n",
      " 'Cleanliness:Food:Comfort & Facilities'\n",
      " 'Food:Comfort & Facilities:Cleanliness'\n",
      " 'Staff:Comfort & Facilities:Value for money'\n",
      " 'Location:Staff:Value for money' 'Comfort & Facilities:Food:Cleanliness'\n",
      " 'Comfort & Facilities:Staff:Value for money'\n",
      " 'Location:Comfort & Facilities:Staff' 'Value for money:Location:Food'\n",
      " 'Food:Location:Cleanliness' 'Staff:Value for money:Cleanliness'\n",
      " 'Staff:Cleanliness:Comfort & Facilities'\n",
      " 'Comfort & Facilities:Staff:Food' 'Comfort & Facilities:Cleanliness:Food'\n",
      " 'Location:Comfort & Facilities:Cleanliness'\n",
      " 'Cleanliness:Comfort & Facilities'\n",
      " 'Staff:Comfort & Facilities:Cleanliness'\n",
      " 'Staff:Comfort & Facilities:Internet'\n",
      " 'Staff:Value for money:Comfort & Facilities'\n",
      " 'Comfort & Facilities:Internet:Food' 'Location:Value for money:Staff'\n",
      " 'Comfort & Facilities:Food:Internet' 'Location:Staff:Internet'\n",
      " 'Internet:Staff:Cleanliness' 'Location:Cleanliness:Staff'\n",
      " 'Location:Cleanliness:Comfort & Facilities'\n",
      " 'Value for money:Comfort & Facilities:Location'\n",
      " 'Food:Internet:Comfort & Facilities' 'Cleanliness:Staff'\n",
      " 'Location:Food:Value for money' 'Internet:Comfort & Facilities:Location'\n",
      " 'Staff:Food:Internet' 'Comfort & Facilities:Cleanliness:Staff'\n",
      " 'Cleanliness:Food' 'Cleanliness:Value for money'\n",
      " 'Food:Cleanliness:Comfort & Facilities' 'Staff:Food:Cleanliness'\n",
      " 'Food:Staff:Cleanliness' 'Food:Staff:Internet'\n",
      " 'Comfort & Facilities:Value for money:Cleanliness'\n",
      " 'Location:Cleanliness:Food' 'Location:Food:Internet'\n",
      " 'Comfort & Facilities:Location:Cleanliness'\n",
      " 'Food:Location:Value for money' 'Staff:Location:Internet'\n",
      " 'Comfort & Facilities:Internet' 'Value for money:Staff:Internet'\n",
      " 'Value for money:Staff:Location' 'Staff:Internet:Value for money'\n",
      " 'Value for money:Food:Location'\n",
      " 'Value for money:Comfort & Facilities:Staff' 'Location:Value for money'\n",
      " 'Cleanliness:Comfort & Facilities:Staff' 'Location:Staff:Cleanliness'\n",
      " 'Food:Cleanliness:Staff' 'Value for money:Staff:Comfort & Facilities'\n",
      " 'Cleanliness:Staff:Comfort & Facilities' 'Cleanliness:Location'\n",
      " 'Location:Internet:Staff' 'Location:Value for money:Cleanliness'\n",
      " 'Food:Comfort & Facilities:Internet' 'Staff:Location:Cleanliness'\n",
      " 'Comfort & Facilities:Internet:Staff' 'Staff:Value for money:Location'\n",
      " 'Staff:Value for money:Internet' 'Food:Value for money:Internet'\n",
      " 'Food:Value for money:Cleanliness' 'Value for money:Location:Internet'\n",
      " 'Location:Cleanliness' 'Staff:Location:Value for money'\n",
      " 'Food:Cleanliness:Value for money'\n",
      " 'Location:Internet:Comfort & Facilities'\n",
      " 'Cleanliness:Value for money:Comfort & Facilities' 'Staff:Internet'\n",
      " 'Cleanliness:Comfort & Facilities:Food' 'Value for money:Cleanliness'\n",
      " 'Staff:Internet:Comfort & Facilities' 'Internet:Comfort & Facilities'\n",
      " 'Comfort & Facilities:Location:Internet'\n",
      " 'Cleanliness:Comfort & Facilities:Location'\n",
      " 'Comfort & Facilities:Cleanliness:Location' 'Cleanliness:Staff:Location'\n",
      " 'Internet' 'Value for money:Location:Cleanliness'\n",
      " 'Value for money:Internet:Location'\n",
      " 'Location:Value for money:Comfort & Facilities'\n",
      " 'Cleanliness:Location:Value for money' 'Value for money:Location:Staff'\n",
      " 'Cleanliness:Internet:Comfort & Facilities' 'Food:Location:Internet'\n",
      " 'Cleanliness:Food:Staff' 'Internet:Staff'\n",
      " 'Cleanliness:Staff:Value for money' 'Food:Cleanliness:Location'\n",
      " 'Comfort & Facilities:Staff:Internet'\n",
      " 'Internet:Food:Comfort & Facilities' 'Cleanliness:Food:Location'\n",
      " 'Location:Food:Cleanliness' 'Location:Internet:Value for money'\n",
      " 'Cleanliness:Location:Food' 'Cleanliness:Location:Comfort & Facilities'\n",
      " 'Comfort & Facilities:Value for money:Internet'\n",
      " 'Internet:Staff:Value for money' 'Comfort & Facilities:Internet:Location'\n",
      " 'Food:Cleanliness' 'Internet:Location'\n",
      " 'Value for money:Staff:Cleanliness'\n",
      " 'Cleanliness:Comfort & Facilities:Value for money'\n",
      " 'Value for money:Location:Comfort & Facilities'\n",
      " 'Food:Internet:Value for money' 'Location:Cleanliness:Value for money'\n",
      " 'Food:Internet' 'Cleanliness:Location:Staff' 'Food:Internet:Location'\n",
      " 'Value for money:Cleanliness:Location' 'Cleanliness:Staff:Food'\n",
      " 'Internet:Comfort & Facilities:Staff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andyb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 107ms/step - accuracy: 0.4172 - loss: 0.6287 - val_accuracy: 0.6623 - val_loss: 0.5059\n",
      "Epoch 2/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 110ms/step - accuracy: 0.6343 - loss: 0.4968 - val_accuracy: 0.6768 - val_loss: 0.4175\n",
      "Epoch 3/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 152ms/step - accuracy: 0.6531 - loss: 0.3956 - val_accuracy: 0.6826 - val_loss: 0.3754\n",
      "Epoch 4/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 130ms/step - accuracy: 0.6499 - loss: 0.3032 - val_accuracy: 0.6072 - val_loss: 0.3770\n",
      "Epoch 5/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 127ms/step - accuracy: 0.6254 - loss: 0.2433 - val_accuracy: 0.6377 - val_loss: 0.3559\n",
      "Epoch 6/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 109ms/step - accuracy: 0.6335 - loss: 0.1966 - val_accuracy: 0.5913 - val_loss: 0.3979\n",
      "Epoch 7/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 103ms/step - accuracy: 0.5986 - loss: 0.1605 - val_accuracy: 0.5478 - val_loss: 0.4187\n",
      "Epoch 8/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 120ms/step - accuracy: 0.5935 - loss: 0.1241 - val_accuracy: 0.5884 - val_loss: 0.4346\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.6163 - loss: 0.3683\n",
      "Test accuracy: 0.6159\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
      "\n",
      "Predicted KPI likelihoods for the sample review:\n",
      "food: 80.60%\n",
      "staff: 99.92%\n",
      "comfort & facilities: 4.35%\n",
      "value for money: 0.60%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, GlobalMaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import glob\n",
    "\n",
    "def load_aspect_data(path):\n",
    "    all_files = glob.glob(path)\n",
    "    all_data = []\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename)\n",
    "        all_data.append(df)\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"Loaded {len(all_files)} CSV files.\")\n",
    "    return combined_df\n",
    "\n",
    "aspect_path = r\"C:\\Users\\andyb\\Desktop\\Coding Files\\PointView\\datasets\\aspect_based_dataset\\*.csv\"\n",
    "aspect_df = load_aspect_data(aspect_path)\n",
    "\n",
    "# Print information about the loaded data\n",
    "print(f\"Total number of rows: {len(aspect_df)}\")\n",
    "print(f\"Columns: {aspect_df.columns.tolist()}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(aspect_df.head())\n",
    "\n",
    "print(\"\\nData types and non-null counts:\")\n",
    "print(aspect_df.info())\n",
    "\n",
    "# Check unique values in the Classification column\n",
    "print(\"\\nUnique values in Classification column:\")\n",
    "print(aspect_df['Classification'].unique())\n",
    "\n",
    "# Define the specific KPIs we're interested in\n",
    "specific_kpis = ['food', 'staff', 'comfort & facilities', 'value for money']\n",
    "\n",
    "# Function to check if a KPI is in the classification\n",
    "def check_kpi(classification, kpi):\n",
    "    if isinstance(classification, str):  # Check if the value is a string\n",
    "        return 1 if kpi.lower() in classification.lower() else 0\n",
    "    return 0  # If it's not a string, return 0\n",
    "\n",
    "# Create binary columns for each specific KPI\n",
    "for kpi in specific_kpis:\n",
    "    aspect_df[kpi] = aspect_df['Classification'].apply(lambda x: check_kpi(x, kpi))\n",
    "\n",
    "# Prepare the features (X) and labels (y)\n",
    "X = aspect_df['Opinion'].values\n",
    "y = aspect_df[specific_kpis].values\n",
    "\n",
    "# Tokenize and pad the text data\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_sequences = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_sequences, maxlen=200)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "input_layer = Input(shape=(200,))\n",
    "embedding_layer = Embedding(10000, 100, input_length=200)(input_layer)\n",
    "lstm_layer = Bidirectional(LSTM(64, return_sequences=True))(embedding_layer)\n",
    "lstm_layer = Bidirectional(LSTM(64, return_sequences=True))(lstm_layer)\n",
    "global_max_pool = GlobalMaxPooling1D()(lstm_layer)\n",
    "dense_layer = Dense(64, activation='relu')(global_max_pool)\n",
    "dropout_layer = Dropout(0.5)(dense_layer)\n",
    "output_layer = Dense(len(specific_kpis), activation='sigmoid')(dropout_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Function to predict KPI likelihoods for new data\n",
    "def predict_kpi_likelihoods(text):\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=200)\n",
    "    prediction = model.predict(padded_sequence)[0]\n",
    "    return {kpi: float(likelihood) for kpi, likelihood in zip(specific_kpis, prediction)}\n",
    "\n",
    "# Test the model on a sample review\n",
    "sample_review = \"The room was clean and comfortable, but the staff was not very friendly. The food was excellent.\"\n",
    "predicted_likelihoods = predict_kpi_likelihoods(sample_review)\n",
    "print(\"\\nPredicted KPI likelihoods for the sample review:\")\n",
    "for kpi, likelihood in predicted_likelihoods.items():\n",
    "    print(f\"{kpi}: {likelihood:.2%}\")\n",
    "\n",
    "# # Function to predict KPIs for your actual dataset\n",
    "# def predict_kpis_for_dataset(df, text_column):\n",
    "#     X_new = df[text_column].values\n",
    "#     X_new_sequences = tokenizer.texts_to_sequences(X_new)\n",
    "#     X_new_padded = pad_sequences(X_new_sequences, maxlen=200)\n",
    "#     predictions = model.predict(X_new_padded)\n",
    "    \n",
    "#     for i, kpi in enumerate(specific_kpis):\n",
    "#         df[f'{kpi}_likelihood'] = predictions[:, i]\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# Use this function on your actual dataset\n",
    "# actual_df = pd.read_csv(\"your_actual_dataset.csv\")\n",
    "# actual_df = predict_kpis_for_dataset(actual_df, 'Review Content')\n",
    "# print(actual_df[['Review Content'] + [f'{kpi}_likelihood' for kpi in specific_kpis]].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
